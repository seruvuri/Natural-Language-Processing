{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af58023b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\z004vc9h\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import re \n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from tensorflow.keras.layers import LSTM,Dense,Embedding,Input\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e01752c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 175621 entries, 0 to 175620\n",
      "Data columns (total 2 columns):\n",
      " #   Column                   Non-Null Count   Dtype \n",
      "---  ------                   --------------   ----- \n",
      " 0   English words/sentences  175621 non-null  object\n",
      " 1   French words/sentences   175621 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 2.7+ MB\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv(\"https://raw.githubusercontent.com/SayamAlt/English-to-French-Language-Translation-using-Seq2Seq-Modeling/main/eng-french.csv\")\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5849379",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnet= WordNetLemmatizer()\n",
    "\n",
    "corpus=[]\n",
    "\n",
    "for i in range(0,len(data)):\n",
    "    review=re.sub('[^a-zA-Z]',' ',data['English words/sentences'][i])\n",
    "    review=review.lower()\n",
    "    review=review.split()\n",
    "    review=[wordnet.lemmatize(word) for word in review if word not in set(stopwords.words('english'))]\n",
    "    review=' '.join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f248920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hi',\n",
       " 'run',\n",
       " 'run',\n",
       " '',\n",
       " 'wow',\n",
       " 'fire',\n",
       " 'help',\n",
       " 'jump',\n",
       " 'stop',\n",
       " 'stop',\n",
       " 'stop',\n",
       " 'wait',\n",
       " 'wait',\n",
       " 'go',\n",
       " 'go',\n",
       " 'go',\n",
       " 'hello',\n",
       " 'hello',\n",
       " 'see',\n",
       " 'try',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'oh',\n",
       " 'attack',\n",
       " 'attack',\n",
       " 'cheer',\n",
       " 'cheer',\n",
       " 'cheer',\n",
       " 'cheer',\n",
       " 'get',\n",
       " 'go',\n",
       " 'go',\n",
       " 'go',\n",
       " 'got',\n",
       " 'got',\n",
       " 'got',\n",
       " 'got',\n",
       " 'got',\n",
       " 'hop',\n",
       " 'hop',\n",
       " 'hug',\n",
       " 'hug',\n",
       " 'fell',\n",
       " 'fell',\n",
       " 'know',\n",
       " 'left',\n",
       " 'left',\n",
       " 'lied',\n",
       " 'lost',\n",
       " 'paid',\n",
       " '',\n",
       " 'ok',\n",
       " 'ok',\n",
       " 'listen',\n",
       " 'way',\n",
       " 'way',\n",
       " 'way',\n",
       " 'way',\n",
       " 'way',\n",
       " 'way',\n",
       " 'way',\n",
       " 'way',\n",
       " 'way',\n",
       " 'really',\n",
       " 'really',\n",
       " 'really',\n",
       " 'thanks',\n",
       " 'try',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'ask tom',\n",
       " 'awesome',\n",
       " 'calm',\n",
       " 'calm',\n",
       " 'calm',\n",
       " 'cool',\n",
       " 'fair',\n",
       " 'fair',\n",
       " 'fair',\n",
       " 'fair',\n",
       " 'fair',\n",
       " 'fair',\n",
       " 'kind',\n",
       " 'nice',\n",
       " 'nice',\n",
       " 'nice',\n",
       " 'nice',\n",
       " 'nice',\n",
       " 'nice',\n",
       " 'beat',\n",
       " 'call',\n",
       " 'call',\n",
       " 'call u',\n",
       " 'call u',\n",
       " 'come',\n",
       " 'come',\n",
       " 'come',\n",
       " 'come',\n",
       " 'come',\n",
       " 'come',\n",
       " 'come',\n",
       " 'come',\n",
       " 'drop',\n",
       " 'drop',\n",
       " 'drop',\n",
       " 'drop',\n",
       " 'get tom',\n",
       " 'get',\n",
       " 'get',\n",
       " 'get',\n",
       " 'get',\n",
       " 'get',\n",
       " 'go away',\n",
       " 'go away',\n",
       " 'go away',\n",
       " 'go away',\n",
       " 'go away',\n",
       " 'go away',\n",
       " 'go away',\n",
       " 'go away',\n",
       " 'go away',\n",
       " 'go away',\n",
       " 'go home',\n",
       " 'go home',\n",
       " 'go home',\n",
       " 'go home',\n",
       " 'go slow',\n",
       " 'go slow',\n",
       " 'goodbye',\n",
       " 'goodbye',\n",
       " 'hang',\n",
       " 'hang',\n",
       " 'hang',\n",
       " 'hang',\n",
       " 'quit',\n",
       " 'quit',\n",
       " 'run',\n",
       " 'help',\n",
       " 'help',\n",
       " 'help',\n",
       " 'help u',\n",
       " 'help u',\n",
       " 'hold',\n",
       " 'hold',\n",
       " 'hug tom',\n",
       " 'agree',\n",
       " 'cried',\n",
       " 'dozed',\n",
       " 'dozed',\n",
       " 'drive',\n",
       " 'smoke',\n",
       " 'snore',\n",
       " 'stink',\n",
       " 'stood',\n",
       " 'stood',\n",
       " 'swore',\n",
       " 'swore',\n",
       " 'tried',\n",
       " 'tried',\n",
       " 'tried',\n",
       " 'waved',\n",
       " 'go',\n",
       " 'tom',\n",
       " 'fat',\n",
       " 'fat',\n",
       " 'fit',\n",
       " 'hit',\n",
       " 'hit',\n",
       " 'ill',\n",
       " 'sad',\n",
       " 'shy',\n",
       " 'wet',\n",
       " 'wet',\n",
       " '',\n",
       " 'join u',\n",
       " 'join u',\n",
       " 'keep',\n",
       " 'keep',\n",
       " 'kiss',\n",
       " 'kiss',\n",
       " '',\n",
       " 'open',\n",
       " 'open',\n",
       " 'perfect',\n",
       " 'see',\n",
       " 'see',\n",
       " 'see',\n",
       " 'see',\n",
       " 'show',\n",
       " 'show',\n",
       " 'shut',\n",
       " 'shut',\n",
       " 'shut',\n",
       " 'shut',\n",
       " 'shut',\n",
       " 'skip',\n",
       " 'long',\n",
       " 'take',\n",
       " 'take',\n",
       " 'take',\n",
       " 'take',\n",
       " 'tell',\n",
       " 'tell',\n",
       " 'tom',\n",
       " 'wake',\n",
       " 'wake',\n",
       " 'wake',\n",
       " 'wake',\n",
       " 'wake',\n",
       " 'wash',\n",
       " 'wash',\n",
       " 'know',\n",
       " 'lost',\n",
       " 'lost',\n",
       " 'lost',\n",
       " 'lost',\n",
       " 'lost',\n",
       " 'lost',\n",
       " 'lost',\n",
       " 'lost',\n",
       " 'lost',\n",
       " 'lost',\n",
       " 'welcome',\n",
       " '',\n",
       " '',\n",
       " 'run',\n",
       " 'fat',\n",
       " 'fat',\n",
       " 'ask',\n",
       " 'ask',\n",
       " 'back',\n",
       " 'back',\n",
       " 'back',\n",
       " 'back',\n",
       " 'back',\n",
       " 'back',\n",
       " 'man',\n",
       " 'man',\n",
       " 'still',\n",
       " 'still',\n",
       " 'still',\n",
       " 'beat',\n",
       " 'beat',\n",
       " 'call tom',\n",
       " 'call tom',\n",
       " 'cheer',\n",
       " 'cool',\n",
       " 'cuff',\n",
       " 'drive',\n",
       " 'drive',\n",
       " 'drive',\n",
       " 'drive',\n",
       " 'find tom',\n",
       " 'find tom',\n",
       " 'fix',\n",
       " 'fix',\n",
       " 'get',\n",
       " 'get',\n",
       " 'get',\n",
       " 'get',\n",
       " 'get',\n",
       " 'get lost',\n",
       " 'get lost',\n",
       " 'get lost',\n",
       " 'get real',\n",
       " 'go ahead',\n",
       " 'go ahead',\n",
       " 'go ahead',\n",
       " 'go ahead',\n",
       " 'go ahead',\n",
       " 'go ahead',\n",
       " 'go ahead',\n",
       " 'good job',\n",
       " 'good job',\n",
       " 'good job',\n",
       " 'grab',\n",
       " 'grab',\n",
       " 'fun',\n",
       " 'fun',\n",
       " 'try',\n",
       " 'wet',\n",
       " 'help tom',\n",
       " 'help tom',\n",
       " 'hi guy',\n",
       " 'cute',\n",
       " 'deep',\n",
       " 'nice',\n",
       " 'nice',\n",
       " 'nice',\n",
       " 'nice',\n",
       " 'hurry',\n",
       " 'hurry',\n",
       " 'hurry',\n",
       " 'hurry',\n",
       " 'ok',\n",
       " 'ok',\n",
       " '',\n",
       " '',\n",
       " 'failed',\n",
       " 'forgot',\n",
       " 'get',\n",
       " 'got',\n",
       " 'got',\n",
       " 'helped',\n",
       " 'jumped',\n",
       " 'looked',\n",
       " 'moaned',\n",
       " 'nodded',\n",
       " 'obeyed',\n",
       " 'phoned',\n",
       " 'phoned',\n",
       " 'refuse',\n",
       " 'refuse',\n",
       " 'rested',\n",
       " 'rested',\n",
       " 'saw',\n",
       " 'saw',\n",
       " 'sighed',\n",
       " 'stayed',\n",
       " 'stayed',\n",
       " 'talked',\n",
       " 'use',\n",
       " 'use',\n",
       " 'use',\n",
       " 'pay',\n",
       " 'try',\n",
       " 'try',\n",
       " 'back',\n",
       " 'back',\n",
       " 'bald',\n",
       " 'busy',\n",
       " 'busy',\n",
       " 'calm',\n",
       " 'cold',\n",
       " 'cool',\n",
       " 'cool',\n",
       " 'deaf',\n",
       " 'deaf',\n",
       " 'done',\n",
       " 'fair',\n",
       " 'fair',\n",
       " 'fair',\n",
       " 'fast',\n",
       " 'fine',\n",
       " 'fine',\n",
       " 'fine',\n",
       " 'free',\n",
       " 'free',\n",
       " 'free',\n",
       " 'full',\n",
       " 'full',\n",
       " 'game',\n",
       " 'game',\n",
       " 'glad',\n",
       " 'home',\n",
       " 'late',\n",
       " 'lazy',\n",
       " 'lazy',\n",
       " 'lazy',\n",
       " 'lazy',\n",
       " 'okay',\n",
       " 'okay',\n",
       " 'rich',\n",
       " 'safe',\n",
       " 'sick',\n",
       " 'sure',\n",
       " 'sure',\n",
       " 'sure',\n",
       " 'sure',\n",
       " 'tall',\n",
       " 'thin',\n",
       " 'tidy',\n",
       " 'tidy',\n",
       " 'ugly',\n",
       " 'ugly',\n",
       " 'weak',\n",
       " 'well',\n",
       " 'well',\n",
       " '',\n",
       " '',\n",
       " 'help',\n",
       " 'hurt',\n",
       " 'work',\n",
       " 'work',\n",
       " 'tom',\n",
       " 'fun',\n",
       " 'fun',\n",
       " '',\n",
       " '',\n",
       " 'new',\n",
       " 'new',\n",
       " 'odd',\n",
       " 'red',\n",
       " 'sad',\n",
       " 'keep',\n",
       " 'keep',\n",
       " 'kiss tom',\n",
       " 'leave',\n",
       " 'leave',\n",
       " 'leave',\n",
       " 'leave u',\n",
       " 'leave u',\n",
       " 'let go',\n",
       " 'let go',\n",
       " 'look',\n",
       " 'look',\n",
       " 'marry',\n",
       " 'marry',\n",
       " 'may go',\n",
       " 'may go',\n",
       " 'may go',\n",
       " 'save tom',\n",
       " 'save tom',\n",
       " 'say',\n",
       " 'came',\n",
       " 'died',\n",
       " 'run',\n",
       " 'sit',\n",
       " 'sit',\n",
       " 'sit',\n",
       " 'sit',\n",
       " 'sit',\n",
       " 'speak',\n",
       " 'speak',\n",
       " 'stand',\n",
       " 'stop tom',\n",
       " 'stop tom',\n",
       " 'taste',\n",
       " 'taste',\n",
       " 'taste',\n",
       " 'taste',\n",
       " 'tell tom',\n",
       " 'tell tom',\n",
       " 'terrific',\n",
       " 'terrific',\n",
       " 'terrific',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'tom came',\n",
       " 'tom died',\n",
       " 'tom knew',\n",
       " 'tom left',\n",
       " 'tom left',\n",
       " 'tom lied',\n",
       " 'tom lie',\n",
       " 'tom lost',\n",
       " 'tom paid',\n",
       " 'late',\n",
       " 'trust',\n",
       " 'trust',\n",
       " 'try hard',\n",
       " 'try',\n",
       " 'try',\n",
       " 'try',\n",
       " 'try',\n",
       " 'use',\n",
       " 'use',\n",
       " 'use',\n",
       " 'use',\n",
       " 'warn tom',\n",
       " 'warn tom',\n",
       " 'watch',\n",
       " 'watch',\n",
       " 'watch u',\n",
       " 'watch u',\n",
       " 'agree',\n",
       " 'go',\n",
       " 'ok',\n",
       " '',\n",
       " '',\n",
       " 'fun',\n",
       " 'fun',\n",
       " 'came',\n",
       " 'died',\n",
       " 'fell',\n",
       " 'quit',\n",
       " '',\n",
       " 'write',\n",
       " 'write',\n",
       " 'lost',\n",
       " 'lost',\n",
       " '',\n",
       " 'aim fire',\n",
       " 'late',\n",
       " 'answer',\n",
       " 'seated',\n",
       " 'seated',\n",
       " 'bird fly',\n",
       " 'bless',\n",
       " 'call home',\n",
       " 'calm',\n",
       " 'calm',\n",
       " 'go',\n",
       " 'go',\n",
       " 'go',\n",
       " 'catch tom',\n",
       " 'catch tom',\n",
       " 'catch',\n",
       " 'chill',\n",
       " 'come back',\n",
       " 'come back',\n",
       " 'come',\n",
       " 'come',\n",
       " 'come',\n",
       " 'come',\n",
       " 'come',\n",
       " 'come',\n",
       " 'come',\n",
       " 'come',\n",
       " 'come',\n",
       " 'come soon',\n",
       " 'come soon',\n",
       " 'cool',\n",
       " 'win',\n",
       " 'win',\n",
       " 'win',\n",
       " '',\n",
       " 'dog bark',\n",
       " 'dog bark',\n",
       " 'ask',\n",
       " 'cry',\n",
       " 'die',\n",
       " 'die',\n",
       " 'lie',\n",
       " 'run',\n",
       " 'run',\n",
       " 'excuse',\n",
       " 'excuse',\n",
       " 'excuse',\n",
       " 'excuse',\n",
       " 'excuse',\n",
       " 'excuse',\n",
       " 'excuse',\n",
       " 'fantastic',\n",
       " 'feel',\n",
       " 'feel',\n",
       " 'feel',\n",
       " 'feel',\n",
       " 'follow',\n",
       " 'follow u',\n",
       " 'follow u',\n",
       " 'forget',\n",
       " 'forget',\n",
       " 'forget',\n",
       " 'forget',\n",
       " 'forget',\n",
       " 'forget',\n",
       " 'forget',\n",
       " 'get job',\n",
       " 'get job',\n",
       " 'get job',\n",
       " 'get job',\n",
       " 'get ready',\n",
       " 'get ready',\n",
       " 'go get',\n",
       " 'go get',\n",
       " 'go inside',\n",
       " 'go bed',\n",
       " 'go bed',\n",
       " 'good luck',\n",
       " 'good luck',\n",
       " 'grab',\n",
       " 'grab',\n",
       " 'grab',\n",
       " 'grab',\n",
       " 'grab',\n",
       " 'grab',\n",
       " 'hand',\n",
       " 'ill',\n",
       " 'old',\n",
       " 'dj',\n",
       " 'good',\n",
       " 'lazy',\n",
       " 'mine',\n",
       " 'rich',\n",
       " 'sexy',\n",
       " '',\n",
       " '',\n",
       " 'hold fire',\n",
       " 'hold fire',\n",
       " 'hold',\n",
       " 'hold',\n",
       " 'hold',\n",
       " 'hold',\n",
       " 'awful',\n",
       " 'weird',\n",
       " 'tom',\n",
       " 'tom',\n",
       " 'cold',\n",
       " 'good',\n",
       " 'okay',\n",
       " 'sick',\n",
       " 'sure',\n",
       " 'sure',\n",
       " 'beg',\n",
       " 'beg',\n",
       " 'beg',\n",
       " 'beg',\n",
       " 'run',\n",
       " 'ski',\n",
       " 'cringed',\n",
       " 'cringed',\n",
       " 'cringed',\n",
       " 'exhaled',\n",
       " 'gave',\n",
       " 'give',\n",
       " 'give',\n",
       " 'got hot',\n",
       " 'got hot',\n",
       " 'fun',\n",
       " 'fun',\n",
       " 'fun',\n",
       " 'fun',\n",
       " 'hate',\n",
       " '',\n",
       " 'hit tom',\n",
       " 'hope',\n",
       " 'hurried',\n",
       " 'hurried',\n",
       " 'inhaled',\n",
       " 'knew',\n",
       " 'like',\n",
       " 'lost',\n",
       " 'love',\n",
       " 'love',\n",
       " 'mean',\n",
       " 'mean',\n",
       " 'must go',\n",
       " 'must go',\n",
       " 'must go',\n",
       " 'must go',\n",
       " 'must go',\n",
       " 'must go',\n",
       " 'must go',\n",
       " 'must go',\n",
       " 'need',\n",
       " 'need',\n",
       " 'noticed',\n",
       " 'prepaid',\n",
       " 'promise',\n",
       " 'relaxed',\n",
       " 'relaxed',\n",
       " 'retired',\n",
       " 'said',\n",
       " 'said',\n",
       " 'saw',\n",
       " 'saw',\n",
       " 'saw',\n",
       " 'saw one',\n",
       " 'saw one',\n",
       " 'saw',\n",
       " 'saw',\n",
       " 'saw',\n",
       " 'saw',\n",
       " 'saw',\n",
       " 'saw',\n",
       " 'saw',\n",
       " 'saw',\n",
       " 'see tom',\n",
       " 'shouted',\n",
       " 'tripped',\n",
       " 'tripped',\n",
       " 'want',\n",
       " 'new',\n",
       " 'new',\n",
       " 'go',\n",
       " 'woke',\n",
       " 'woke',\n",
       " 'agree',\n",
       " 'leave',\n",
       " 'call',\n",
       " 'cook',\n",
       " 'help',\n",
       " 'live',\n",
       " 'obey',\n",
       " 'pack',\n",
       " 'pack',\n",
       " 'pack',\n",
       " 'pas',\n",
       " 'quit',\n",
       " 'sing',\n",
       " 'stop',\n",
       " 'swim',\n",
       " 'talk',\n",
       " 'talk',\n",
       " 'wait',\n",
       " 'walk',\n",
       " 'work',\n",
       " 'work',\n",
       " 'cop',\n",
       " 'man',\n",
       " 'alive',\n",
       " 'alive',\n",
       " 'alive',\n",
       " 'alone',\n",
       " 'alone',\n",
       " 'angry',\n",
       " 'angry',\n",
       " 'armed',\n",
       " 'armed',\n",
       " 'awake',\n",
       " 'blind',\n",
       " 'broke',\n",
       " 'clean',\n",
       " 'clean',\n",
       " 'crazy',\n",
       " 'crazy',\n",
       " 'cured',\n",
       " 'cured',\n",
       " 'dizzy',\n",
       " 'drunk',\n",
       " 'drunk',\n",
       " 'drunk',\n",
       " 'dying',\n",
       " 'early',\n",
       " 'first',\n",
       " 'fussy',\n",
       " 'fussy',\n",
       " 'fussy',\n",
       " 'going',\n",
       " 'going',\n",
       " 'going',\n",
       " 'going',\n",
       " 'loyal',\n",
       " 'loyal',\n",
       " 'lucky',\n",
       " 'lucky',\n",
       " 'lucky',\n",
       " 'lucky',\n",
       " 'lucky',\n",
       " 'lying',\n",
       " 'naked',\n",
       " 'naked',\n",
       " 'naked',\n",
       " 'naked',\n",
       " 'naked',\n",
       " 'quiet',\n",
       " 'ready',\n",
       " 'ready',\n",
       " 'ready',\n",
       " 'right',\n",
       " 'sober',\n",
       " 'sorry',\n",
       " 'sorry',\n",
       " 'sorry',\n",
       " 'sorry',\n",
       " 'sorry',\n",
       " 'sorry',\n",
       " 'stuck',\n",
       " 'timid',\n",
       " 'tired',\n",
       " 'tough',\n",
       " 'tough',\n",
       " 'tough',\n",
       " 'tough',\n",
       " '',\n",
       " '',\n",
       " 'lost',\n",
       " 'tom ok',\n",
       " 'tom ok',\n",
       " 'bad',\n",
       " 'far',\n",
       " 'far',\n",
       " 'hot',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'failed',\n",
       " 'snowed',\n",
       " 'stink',\n",
       " 'stink',\n",
       " 'ok',\n",
       " 'ok',\n",
       " 'ok',\n",
       " 'worked',\n",
       " 'worked',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'tv',\n",
       " 'cold',\n",
       " 'cold',\n",
       " 'dark',\n",
       " 'dead',\n",
       " 'dead',\n",
       " 'dead',\n",
       " 'done',\n",
       " 'easy',\n",
       " 'food',\n",
       " 'free',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'late',\n",
       " 'lost',\n",
       " 'mine',\n",
       " 'mine',\n",
       " 'mine',\n",
       " 'mine',\n",
       " 'open',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'sand',\n",
       " 'time',\n",
       " 'time',\n",
       " 'true',\n",
       " 'work',\n",
       " 'keep calm',\n",
       " 'keep',\n",
       " 'keep',\n",
       " 'keep',\n",
       " 'keep',\n",
       " 'let',\n",
       " 'let',\n",
       " 'let go',\n",
       " 'let go',\n",
       " 'let go',\n",
       " 'let go',\n",
       " 'let go',\n",
       " 'let go',\n",
       " 'let go',\n",
       " 'let go',\n",
       " 'let go',\n",
       " 'let go',\n",
       " 'let go',\n",
       " 'let go',\n",
       " 'let',\n",
       " 'let',\n",
       " 'let ask',\n",
       " 'let eat',\n",
       " 'let see',\n",
       " 'lie still',\n",
       " 'lie still',\n",
       " 'lie still',\n",
       " 'lie still',\n",
       " 'lie still',\n",
       " 'lie still',\n",
       " 'look away',\n",
       " 'look away',\n",
       " 'look back',\n",
       " 'look back',\n",
       " 'look',\n",
       " 'look',\n",
       " 'loosen',\n",
       " 'loosen',\n",
       " 'loosen',\n",
       " 'loosen',\n",
       " 'loosen',\n",
       " 'move',\n",
       " 'move',\n",
       " 'move',\n",
       " 'nice shot',\n",
       " 'course',\n",
       " 'course',\n",
       " 'course',\n",
       " 'course',\n",
       " 'course',\n",
       " 'oh please',\n",
       " 'oh please',\n",
       " 'pardon',\n",
       " 'pardon',\n",
       " 'pardon',\n",
       " 'read',\n",
       " 'say hello',\n",
       " 'see',\n",
       " 'see',\n",
       " 'see',\n",
       " 'seize',\n",
       " 'seize',\n",
       " 'seriously',\n",
       " 'seriously',\n",
       " 'seriously',\n",
       " 'cried',\n",
       " 'cried',\n",
       " 'tried',\n",
       " 'walk',\n",
       " 'hot',\n",
       " 'hot',\n",
       " 'sign',\n",
       " 'sign',\n",
       " 'sign',\n",
       " 'sign',\n",
       " 'slow',\n",
       " 'slow',\n",
       " 'stay away',\n",
       " 'stay away',\n",
       " 'stay back',\n",
       " 'stay back',\n",
       " 'stay calm',\n",
       " 'stay calm',\n",
       " 'stay calm',\n",
       " 'stay calm',\n",
       " 'stay calm',\n",
       " 'stay',\n",
       " 'stay',\n",
       " 'stay',\n",
       " 'stay',\n",
       " 'stay',\n",
       " 'stay',\n",
       " 'stay',\n",
       " 'stay thin',\n",
       " 'step back',\n",
       " 'step back',\n",
       " 'stop',\n",
       " 'stop',\n",
       " 'stop',\n",
       " 'stop',\n",
       " 'stop',\n",
       " 'take care',\n",
       " 'take care',\n",
       " 'take care',\n",
       " 'take care',\n",
       " 'take mine',\n",
       " 'take mine',\n",
       " 'take mine',\n",
       " 'take mine',\n",
       " 'take mine',\n",
       " 'take mine',\n",
       " 'take mine',\n",
       " 'take mine',\n",
       " 'take',\n",
       " 'take',\n",
       " 'thank',\n",
       " 'thank',\n",
       " 'ok',\n",
       " 'ok',\n",
       " 'ok',\n",
       " 'ok',\n",
       " '',\n",
       " '',\n",
       " 'fell',\n",
       " 'fell',\n",
       " 'left',\n",
       " 'left',\n",
       " 'lied',\n",
       " 'lied',\n",
       " 'lost',\n",
       " 'lost',\n",
       " 'swam',\n",
       " 'swam',\n",
       " 'swam',\n",
       " 'swam',\n",
       " 'time',\n",
       " 'tom cook',\n",
       " 'tom cried',\n",
       " 'tom ok',\n",
       " 'tom knit',\n",
       " 'tom know',\n",
       " 'tom rock',\n",
       " 'tom spoke',\n",
       " 'tom waved',\n",
       " 'tom work',\n",
       " 'tom fat',\n",
       " 'tom mad',\n",
       " 'tom mad',\n",
       " 'tom sad',\n",
       " 'trust tom',\n",
       " 'trust tom',\n",
       " 'try',\n",
       " 'try',\n",
       " 'try',\n",
       " 'try',\n",
       " 'turn left',\n",
       " 'wait',\n",
       " 'wait',\n",
       " 'wait',\n",
       " 'wait',\n",
       " 'watch',\n",
       " 'watch',\n",
       " 'watch',\n",
       " 'agreed',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'forgot',\n",
       " 'saw',\n",
       " 'saw',\n",
       " 'smiled',\n",
       " 'talked',\n",
       " 'talked',\n",
       " 'talked',\n",
       " 'talked',\n",
       " 'talked',\n",
       " 'waited',\n",
       " 'waited',\n",
       " 'walked',\n",
       " 'walked',\n",
       " 'try',\n",
       " 'try',\n",
       " 'win',\n",
       " 'win',\n",
       " 'hot',\n",
       " 'sad',\n",
       " ...]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24330d55",
   "metadata": {},
   "source": [
    "### Onehot Representation\n",
    "\n",
    "    If we set voc_size=10000, it means that you are limiting your vocabulary to the 10,000 most frequent words in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53a5f9c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4029], [2714], [2714], [], [7840], [4398], [6163], [7444], [9218], [9218]]\n"
     ]
    }
   ],
   "source": [
    "voc_size=10000\n",
    "\n",
    "onehot_rep=[one_hot(word,voc_size) for word in corpus]\n",
    "print(onehot_rep[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb437a4c",
   "metadata": {},
   "source": [
    "### Padding Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "508ce0e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0 ...    0    0 4029]\n",
      " [   0    0    0 ...    0    0 2714]\n",
      " [   0    0    0 ...    0    0 2714]\n",
      " ...\n",
      " [   0    0    0 ... 6280  102 4540]\n",
      " [4612 4694 5087 ...  800 8179 7417]\n",
      " [6030   53 9342 ... 9342   98 6540]]\n"
     ]
    }
   ],
   "source": [
    "sent_length=20\n",
    "embedded_docs=pad_sequences(onehot_rep,padding='pre',maxlen=sent_length)\n",
    "print(embedded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ac0a892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175621"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7b3cd8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0 4029]\n"
     ]
    }
   ],
   "source": [
    "print(embedded_docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6596fb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features=20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446cacb8",
   "metadata": {},
   "source": [
    "### Encoders and Decoders Model \n",
    "\n",
    "    The dimensionality of the embedding space. This is the size of the dense vector to represent each word. For example, if you set embedding_vector_features to 100, each word in your vocabulary will be represented as a 100-dimensional vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38e10e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\z004vc9h\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Encoder model\n",
    "embeding_vector_features=40\n",
    "\n",
    "encoder_model=Sequential()\n",
    "\n",
    "encoder_model.add(Embedding(voc_size,embeding_vector_features,input_length=sent_length))\n",
    "encoder_model.add(LSTM(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09d2b102",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decoder Model \n",
    "\n",
    "Decoder_model=Sequential()\n",
    "\n",
    "Decoder_model.add(Embedding(voc_size,embeding_vector_features,input_length=sent_length))\n",
    "Decoder_model.add(LSTM(100))\n",
    "Decoder_model.add(Dense(voc_size,activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ee757462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential (Sequential)     (None, 100)               456400    \n",
      "                                                                 \n",
      " sequential_2 (Sequential)   (None, 10000)             1466400   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1922800 (7.33 MB)\n",
      "Trainable params: 1922800 (7.33 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "encoder_decoder_model=Sequential(\n",
    "            [encoder_model,\n",
    "            Decoder_model])\n",
    "encoder_decoder_model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "print(encoder_decoder_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e4f7e5d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((175621, 20), (175621,))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=data['French words/sentences']\n",
    "\n",
    "X_final=np.array(embedded_docs)\n",
    "y_final=np.array(y)\n",
    "\n",
    "X_final.shape,y_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5b678017",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X_final,y_final,random_state=0,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "590280a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\z004vc9h\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\z004vc9h\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\z004vc9h\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\z004vc9h\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1150, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\z004vc9h\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\z004vc9h\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential_4' (type Sequential).\n    \n    Input 0 of layer \"sequential_2\" is incompatible with the layer: expected shape=(None, 20), found shape=(None, 100)\n    \n    Call arguments received by layer 'sequential_4' (type Sequential):\n      • inputs=tf.Tensor(shape=(None, 20), dtype=int32)\n      • training=True\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m encoder_decoder_model\u001b[38;5;241m.\u001b[39mfit(X_train,y_train,validation_data\u001b[38;5;241m=\u001b[39m(X_test,y_test),epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileup_8maab.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\z004vc9h\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\z004vc9h\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\z004vc9h\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\z004vc9h\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1150, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\z004vc9h\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\z004vc9h\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential_4' (type Sequential).\n    \n    Input 0 of layer \"sequential_2\" is incompatible with the layer: expected shape=(None, 20), found shape=(None, 100)\n    \n    Call arguments received by layer 'sequential_4' (type Sequential):\n      • inputs=tf.Tensor(shape=(None, 20), dtype=int32)\n      • training=True\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "encoder_decoder_model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77b3368",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
